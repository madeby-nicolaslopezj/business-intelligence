library(ROCR)
library(e1071)
library(cvTools) #crossvalidation
setwd("/Users/nicolaslopezj/Code/r/bi")
bupa<-read.table("8-29/cmc.data",header = FALSE,sep=",")
bupa<-read.table("./8-29/cmc.data",header = FALSE,sep=",")
bupa<-read.table("/Users/nicolaslopezj/Code/r/bi/8-29/cmc.data",header = FALSE,sep=",")
setwd("/Users/nicolaslopezj/Code/r/bi")
bupa<-read.table("/Users/nicolaslopezj/Code/r/bi/8-29/cmc.data",header = FALSE,sep=",")
file
file.open
bupa<-read.table(file.open("8-29/cmc.data"),header = FALSE,sep=",")
file
file.open
file.openfo
fole
file
bupa<-read.table(file("8-29/cmc.data"),header = FALSE,sep=",")
bupa<-read.table(file(open="8-29/cmc.data"),header = FALSE,sep=",")
sub <- sample(nrow(bupa), floor(nrow(bupa) * 0.7))
bupa<-read.table(file.choose(),header = FALSE,sep=",")
"8-29/cmc.data"
cd "8-29/cmc.data"
wd
bupa<-read.table("./8-29/cmc.data",header = FALSE,sep=",")
bupa<-read.table("./8-29/cmc.data",header = FALSE,sep=",")
bupa<-read.table("/Users/nicolaslopezj/Code/r/bi/8-29/cmc.data",header = FALSE,sep=",")
bupa<-read.table("/8-29/cmc.data",header = FALSE,sep=",")
bupa<-read.table("8-29/cmc.data",header = FALSE,sep=",")
bupa<-read.table("8\-29/cmc.data",header = FALSE,sep=",")
bupa<-read.table("8-29/cmc.data",header = FALSE,sep=",")
bupa<-read.table(file.choose(),header = FALSE,sep=",")
sub <- sample(nrow(bupa), floor(nrow(bupa) * 0.7))
train_bupa<-bupa[sub, ] #train set 70 %
test_bupa<-bupa[-sub, ] #test set 30%
a=naiveBayes(V7~.,data=train_bupa)
output=predict(a,test_bupa[,-7],type="raw")
pred1=max.col(output)
CM=table(pred1,test_bupa[,7]) #confusion matrix
CM
#Accuracy
(CM[1,1]+CM[2,2])/(CM[1,1]+CM[1,2]+CM[2,1]+CM[2,2])
# ROCR
pred <- prediction(output[,2],test_bupa[,7])
perf <- performance(pred, measure = "acc")
plot(perf, col=rainbow(10))
y=max(data.frame(perf@y.values))
y
indice=which(data.frame(perf@y.values)== max(data.frame(perf@y.values)) )
cutpoint=perf@x.values[[1]][[indice[1]]]
cutpoint
#using the cutpoint (threshold)
pred2=ifelse(output[,2]>=cutpoint,2,1)
CM=table(test_bupa[,7],pred2)
CM
library(mlbench)
data(BreastCancer)
View(BreastCancer)
View(BreastCancer)
data <- data(BreastCancer)
data
# Load data
data(BreastCancer)
BreastCancer
# Set training and testing sets
sub <- sample(nrow(BreastCancer), floor(nrow(BreastCancer) * 0.7))
train<-BreastCancer[sub, ] #train set 70 %
test<-BreastCancer[-sub, ] #test set 30%
BreastCancer
summary(BreastCancer)
train
library(rpart)
# Load data
data(BreastCancer)
# Set training and testing sets
sub <- sample(nrow(BreastCancer), floor(nrow(BreastCancer) * 0.7))
train<-BreastCancer[sub, ] #train set 70 %
test<-BreastCancer[-sub, ] #test set 30%
# naivebayes
naiveBayes <- naiveBayes(Class~.,data=train)
# DT
rpart.tree <- rpart(Class ~ ., data=train)
plot(rpart.tree,margin=0.2)
text (rpart.tree, use.n = T, pretty = TRUE)
title("Training Set's Classification Tree")
BreastCancer
summary(BreastCancer)
BreastCancer$Id <- as.factor(BreastCancer$Id)
summary(BreastCancer)
# Load libraries
library(mlbench)
library(rpart)
# Load data
data(BreastCancer)
BreastCancer$Id <- as.factor(BreastCancer$Id)
# Set training and testing sets
sub <- sample(nrow(BreastCancer), floor(nrow(BreastCancer) * 0.7))
train<-BreastCancer[sub, ] #train set 70 %
test<-BreastCancer[-sub, ] #test set 30%
# naivebayes
naiveBayes <- naiveBayes(Class~.,data=train)
# DT
rpart.tree <- rpart(Class ~ ., data=train)
plot(rpart.tree,margin=0.2)
text (rpart.tree, use.n = T, pretty = TRUE)
title("Training Set's Classification Tree")
summary(BreastCancer)
BreastCancer$Id <- as.factor(BreastCancer$Id)
BreastCancer$Id <- as.factor(BreastCancer$Id)
summary(BreastCancer)
data(BreastCancer)
BreastCancer <- BreastCancer[-Id]
BreastCancer <- BreastCancer[,Id]
BreastCancer <- BreastCancer[,-Id]
BreastCancer <- BreastCancer[,-~Id]
BreastCancer$Id <- NULL
summary(BreastCancer)
# Set training and testing sets
sub <- sample(nrow(BreastCancer), floor(nrow(BreastCancer) * 0.7))
train<-BreastCancer[sub, ] #train set 70 %
test<-BreastCancer[-sub, ] #test set 30%
# naivebayes
naiveBayes <- naiveBayes(Class~.,data=train)
# DT
rpart.tree <- rpart(Class ~ ., data=train)
plot(rpart.tree,margin=0.2)
text (rpart.tree, use.n = T, pretty = TRUE)
naiveBayes
predictions <- predict(rpart.tree, test, type="class")
table(test$Class, predictions)
naiveAlgo <- naiveBayes(Class~.,data=train)
output=predict(naiveAlgo, test, type="raw")
predictNaive=max.col(output)
CM=table(predictNaive,train) #confusion matrix
CM
a=naiveBayes(V7~.,data=train_bupa)
output=predict(a,test_bupa[,-7],type="raw")
pred1=max.col(output)
CM=table(pred1,test_bupa[,7]) #confusion matrix
CM
test$-Class
test-$Class
test$Class
test
summary(test)
test[, -7]
test[, 7]
test[, 6]
test[, 5]
test[, $Class]
test
summary(test)
naiveAlgo <- naiveBayes(Class~.,data=train)
output=predict(naiveAlgo, test[, -10], type="raw")
predictNaive=max.col(output)
CM=table(predictNaive,test[, 10]) #confusion matrix
CM
naiveAlgo <- naiveBayes(Class~.,data=train)
output=predict(naiveAlgo, test[, -10], type="raw")
predictNaive=max.col(output)
CMN=table(predictNaive, test[, 10]) #confusion matrix
CMN
#Accuracy
accuracyNaive <- (CMN[1,1]+CMN[2,2])/(CMN[1,1]+CMN[1,2]+CMN[2,1]+CMN[2,2])
accuracyNaive
predictNaive=max.col(output)
confusionMatrix=table(predictNaive, test[, 10]) #confusion matrix
confusionMatrix
#Accuracy
accuracyNaive <- accuracy <- sum(diag(confusionMatrix)) / sum(confusionMatrix)
accuracyNaive
# Desition Tree
rpart.tree <- rpart(Class ~ ., data=train)
plot(rpart.tree, margin=0.5)
text (rpart.tree, use.n = T, pretty = TRUE)
plot(rpart.tree, margin=0.1)
text (rpart.tree, use.n = T, pretty = TRUE)
plot(rpart.tree, margin=0.05)
text (rpart.tree, use.n = T, pretty = TRUE)
title("Training Set's Classification Tree")
rpart.predictions <- predict(rpart.tree, test, type="class")
table(test$Class, predictions)
rpart.predictions <- predict(rpart.tree, test, type="class")
rpart.confusion <- table(test$Class, predictions)
rpart.accuracy <- accuracy <- sum(diag(rpart.confusion)) / sum(rpart.confusion)
rpart.accuracy
perf <- performance(predictNaive, measure = "tpr", x.measure = "fpr")
plot(perf, col=rainbow(10))
plot(perf, col=rainbow(10),print.cutoffs.at=cutpoint)
# ROC Curve
perf <- performance(predictNaive, measure = "tpr", x.measure = "fpr")
#ROC curve
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, col=rainbow(10))
plot(perf, col=rainbow(10),print.cutoffs.at=cutpoint)
x
#AUC: area under the curve
perf <- performance(pred, measure = "auc")
auc<-perf@y.values[[1]]
auc
perf <- performance(predictNaive, measure = "tpr", x.measure = "fpr")
predictNaive
perf <- performance(output, measure = "tpr", x.measure = "fpr")
perf <- performance(output, measure = "tpr", x.measure = "fpr")
plot(perf, col=rainbow(10))
output
output[,2]
# ROC Curve
pred <- prediction(output[,2],test[, 10])
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, col=rainbow(10))
plot(perf, col=rainbow(10), print.cutoffs.at=cutpoint)
library(cvTools) #crossvalidation
bupa<-read.table(file.choose(),header = FALSE,sep=",")
sub <- sample(nrow(bupa), floor(predclass <- predict(bayes, newdata=test[,-7], type='raw')
pred1=max.col(predclass)nrow(bupa) * 0.7))
train_bupa<-bupa[sub, ] #train set 70 %
test_bupa<-bupa[-sub, ] #test set 30%
a=naiveBayes(V7~.,data=train_bupa)
output=predict(a,test_bupa[,-7],type="raw")
pred1=max.col(output)
CM=table(pred1,test_bupa[,7]) #confusion matrix
CM
#Accuracy
(CM[1,1]+CM[2,2])/(CM[1,1]+CM[1,2]+CM[2,1]+CM[2,2])
# ROCR
pred <- prediction(output[,2],test_bupa[,7])
perf <- performance(pred, measure = "acc")
plot(perf, col=rainbow(10))
y=max(data.frame(perf@y.values))
# ROC Curve
pred <- prediction(output[,2],test[, 10])
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, col=rainbow(10))
plot(perf, col=rainbow(10), print.cutoffs.at=cutpoint)
# Naive Bayer
naiveAlgo <- naiveBayes(Class~.,data=train)
output=predict(naiveAlgo, test[, -10], type="raw")
predictNaive=max.col(output)
confusionMatrix=table(predictNaive, test[, 10]) #confusion matrix
confusionMatrix
# Accuracy
accuracyNaive <- sum(diag(confusionMatrix)) / sum(confusionMatrix)
accuracyNaive
# ROC Curve
pred <- prediction(output[,2],test[, 10])
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, col=rainbow(10))
plot(perf, col=rainbow(10), print.cutoffs.at=cutpoint)
perf <- performance(pred)
plot(perf, col=rainbow(10))
plot(perf, col=rainbow(10), print.cutoffs.at=cutpoint)
rpart.pred <- prediction(rpart.predictions[,2],test[, 10])
# Accuracy
rpart.predictions <- predict(rpart.tree, test, type="class")
rpart.confusion <- table(test$Class, predictions)
rpart.accuracy <- sum(diag(rpart.confusion)) / sum(rpart.confusion)
rpart.accuracy
# ROC Curve
rpart.pred <- prediction(rpart.predictions[,2],test[, 10])
rpart.predictions
rpart.predictions[,2]
rpart.pred <- prediction(rpart.predictions[,1], test[, 10])
summary(rpart.predictions)
rpart.pred
rpart.confusion <- table(rpart.predictions$Class, predictions)
rpart.predictions
rpart.tree <- rpart(Class ~ ., data=train)
rpart.predictions <- predict(rpart.tree, test, type="class")
rpart.predictions
predictions
predictions[0]
predictions[,0]
predictions[,1]
predictions[1]
predictions$1
predictions[, 1]
predictions[, 2]
predictions
rpart.predictions
rpart.tree <- rpart(Class ~ ., data=train)
rpart.predictions <- predict(rpart.tree, test, type="class")
plot(rpart.tree, margin=0.05)
text (rpart.tree, use.n = T, pretty = TRUE)
title("Training Set's Classification Tree")
# Accuracy
rpart.confusion <- table(test$Class, rpart.predictions)
rpart.accuracy <- sum(diag(rpart.confusion)) / sum(rpart.confusion)
rpart.accuracy
# ROC Curve
rpart.pred <- prediction(rpart.predictions[,1], test[, 10])
rpart.predictions
rpart.predictions[1]
rpart.pred <- prediction(rpart.predictions, test[, 10])
rpart.predictions
predictNaive
rpart.predictions <- predict(rpart.tree, test, type="class")
rpart.predictCol <- max.col(output)
plot(rpart.tree, margin=0.05)
rpart.predictCol
rpart.pred <- prediction(rpart.predictCol, test[, 10])
rpart.perf <- performance(rpart.pred, measure = "tpr", x.measure = "fpr")
plot(rpart.perf, col=rainbow(10))
plot(rpart.perf, col=rainbow(10), print.cutoffs.at=cutpoint)
# Desition Tree
##
rpart.tree <- rpart(Class ~ ., data=train)
rpart.predictions <- predict(rpart.tree, test, type="class")
rpart.predictCol <- max.col(output)
plot(rpart.tree, margin=0.05)
text (rpart.tree, use.n = T, pretty = TRUE)
title("Training Set's Classification Tree")
# Accuracy
rpart.confusion <- table(test$Class, rpart.predictions)
rpart.accuracy <- sum(diag(rpart.confusion)) / sum(rpart.confusion)
rpart.accuracy
# ROC Curve
rpart.pred <- prediction(rpart.predictCol, test[, 10])
rpart.perf <- performance(rpart.pred, measure = "tpr", x.measure = "fpr")
plot(rpart.perf, col=rainbow(10))
plot(rpart.perf, col=rainbow(10), print.cutoffs.at=cutpoint)
rpart.pred
rpart.perf
rpart.perf <- performance(rpart.pred, measure = "tpr", x.measure = "fpr")
plot(rpart.perf, col=rainbow(10))
plot(rpart.perf, col=rainbow(10), print.cutoffs.at=cutpoint)
confusionMatrix
rpart.confusion
accuracyNaive
confusionMatrix
rpart.confusion <- table(test$Class, rpart.predictions)
rpart.confusion
rpart.accuracy
