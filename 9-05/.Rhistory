result
name(results)
name(result)
names(result)
c('amount')
query(c('amount'))
result(c('amount'))
result[c('amount')]
data <- result[c('amount')]
data <- result[c('amount', 'stats.rentability')]
data <- result[c('amount', 'stats')]
data
dim(iris)
#Name of variables or columns
names(iris)
#Structure
data<-readWorksheetFromFile(file.choose(), sheet=1)
library("XLConnect")
data<-readWorksheetFromFile(file.choose(), sheet=1)
plot(data)
cor(data)
sueldo <- 100000
sueldo <- 100000
<-?
sueldo <- 100000
if (sueldo < 200000) {
print(1)
sueldo <- 100000
if (sueldo < 200000) {
print(1)
}
plot(data)
library("XLConnect")
data<-readWorksheetFromFile(file.choose(), sheet=1)
plot(data)
mayor40 <- data[data[, "Edad"] > 40,]
mayor40
data
plot(mayor40)
mayor40[1]
mayor40[1]
mayor40[2]
mayor40[, 1]
mayor40[, 2]
mayor40[1, 1]
mayor40
print(1)
print(3131341)
for (row in mayor40) {
print(row)
}
mayor40 <- data[data[, "Edad"] > 40,]
for (row in mayor40) {
print(row)
}
table(mayor40)
iris
dim(iris)
#Name of variables or columns
dim(iris)
names(iris)
#Structure
str(iris)
attributes(iris)
iris[1:5,]
iris[1:10, "Sepal.Length"]
summary(iris)
table(iris$Species)
pie(table(iris$Species))
mean(iris$Sepal.Length)
var(iris$Sepal.Length)
#Standard Deviation of Sepal.Length
sd(iris$Sepal.Length)
#Covariance of two variables
cov(iris$Sepal.Length, iris$Petal.Length)
#Correlation of two variables
cor(iris$Sepal.Length, iris$Petal.Length)
#Correlation matrix
cor(iris[,-5])
#Distribution of subsets
aggregate(Sepal.Length ~ Species, summary, data=iris)
#Box plots
boxplot(Sepal.Length~Species, data=iris)
library("XLConnect")
data<-readWorksheetFromFile(file.choose(), sheet=1)
plot(data)
summary(data)
data
data[]
data[1]
data["Contacto"]
data["Contacto"]
data["Contacto",]
data<-readWorksheetFromFile(file.choose(), sheet='Hoja1')
plot(data)
data["Contacto",]
data["Contacto",]
data
View(data)
View(data)
data<-readWorksheetFromFile(file.choose(), sheet=1)
data
refer<-readWorksheetFromFile(file.choose(), sheet=1)
refer
dat = read.csv("cities.csv", header = TRUE)
dat = read.csv(file.choose(), header = TRUE)
data = read.csv(file.choose(), header = TRUE)
dat
data
plot(data)
cov(data)
cor(data)
cor(data$1)
cor(data[1])
cor(data[-1])
cor(data[-1,])
cor(data[-1])
pairs(data)
pairs(data)
cor.test(data[-1])
cor.test(data)
cor.test(data, data)
cor.test(data[-1], data[-1])
cor(data)
cor(data[-1])
cor(data[-1])
CM <- cor(data[-1])
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), value > .85)
c(-1)
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), value > .6)
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), value > .6 && value != 1)
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), (value > .6 && value != 1))
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), value < .6)
print(1)
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), check)
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), check(valye))
check <- function(value) {
print(value)
}
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), check(value))
return false
check <- function(value) {
print(value)
return false
}
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), check(value))
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), check)
check <- function(value) {
print(value)
if (value === 1) return false
if (value < -0.6) return true
if (value > -0.6) return true
}
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), check(value))
check <- function(value) {
if (value === 1) return false
if (value < -0.6) return true
if (value > -0.6) return true
}
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), check(value))
check <- function(value) {
if (value === 1) return false
if (value < -0.6) return true
if (value > -0.6) return true
}
check <- function (value) {
if (value === 1) return false
if (value < -0.6) return true
if (value > -0.6) return true
}
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), check(value))
check <- function (value) {
if (value === 1) return false
if (value < -0.6) return true
if (value > -0.6) return true
}
check = function (value) {
if (value === 1) return false
if (value < -0.6) return true
if (value > -0.6) return true
}
check <- function (value)
{
if (value === 1) return false
if (value < -0.6) return true
if (value > -0.6) return true
}
check <- function (value)
{
if (value === 1) return false
if (value < -0.6) return true
if (value > -0.6) return true
}
check <- function (value)
{
if (value === 1)
return false
if (value < -0.6)
return true
check <- function (value)
{
if (value == 1)
return false
if (value < -0.6)
return true
if (value > -0.6)
return true
}
check <- function (value)
{
if (value == 1)
return(false)
if (value < -0.6)
return(true)
if (value > -0.6)
return(true)
}
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), check(value))
check <- function (value)
{
print(value)
if (value == 1)
return(false)
if (value < -0.6)
return(true)
if (value > -0.6)
return(true)
}
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), check(value))
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), check)
check <- function (value)
{
print(value)
return(false)
}
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), check)
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), check)
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), value > 0.5)
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), value > 0.6)
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), value > 0.6)
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), value < -0.6)
CM <- cor(data[-1])
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), value > 0.65)
subset(na.omit(data.frame(expand.grid(dimnames(CM)), value = c(CM))), value < -0.65)
view(data)
View(data)
data
data[-1]
withOutCity <- data[, -1]
data[, -1]
cor(data[,-1])
withOutCity <- data[, -1]
plot(withOutCity)
cor(withOutCity)
withOutCityScaled <- scale(withOutCity)
withOutCityScaled
out.pca
out.pca<-PRM
PRM
PCA
pca
out.pca<-PRM(withOutCityScaled)
out.pca<-PVM(withOutCityScaled)
prcomp(withOutCityScaled)
out.pca<- prcomp(withOutCityScaled)
summary(out.pca)
plot(out.pca$x[,1:2])
withOutCity
#Generate training and testing set
sub <- sample(nrow(iris), floor(nrow(iris) * 0.7))
train.set<-iris[sub, ] #70 % for training
test.set<-iris[-sub, ] #30 % for testing
library(rpart)
rpart.tree <- rpart(Species ~ ., data=train.set)
plot(rpart.tree,margin=0.2)
text (rpart.tree, use.n = T, pretty = TRUE)
title("Training Set's Classification Tree")
#prediction using test set
predictions <- predict(rpart.tree, test.set, type="class")
#Compare with real labels through the confusion matrix
table(test.set$Species, predictions)
#Prune
prune.rpart.tree <- prune(rpart.tree, cp=0.01)
plot(prune.rpart.tree,margin=0.2)
text (prune.rpart.tree, use.n = T, pretty = TRUE)
#control parameters (minimum number for split)
rpart.tree <- rpart(Species ~ ., data=train.set,control = rpart.control(minsplit=5))
plot(rpart.tree,margin=0.2)
text (rpart.tree, use.n = T, pretty = TRUE)
###################################################
### prediccion usando datos de la encuesta Adult
###################################################
#Train:
Adult<-read.csv(file.choose(),header = FALSE,sep=";")
m <- rpart(V15~.,data=Adult)
plot(m,margin=0.2)
text(m, use.n=T,pretty=TRUE)
post(m, file = "/Users/gonzaloruz/Desktop/tree2.ps",
title = "Classification Tree for Adult dataset")
# Test:
AdultTest<-read.csv(file.choose(),header = FALSE,sep=";")
data <- read.csv("cmc.data", header = FALSE, sep=",")
setwd("/Users/nicolaslopezj/Code/r/bi/9-05")
data <- read.csv("cmc.data", header = FALSE, sep=",")
data
# Set working directory
setwd("/Users/nicolaslopezj/Code/r/bi/9-05")
# Set data
data <- read.csv("cmc.data", header = FALSE, sep=",")
# Set the seed
set.seed(1111)
data <- read.csv("cmc.data", header = FALSE, sep=",")
#Generate training and testing set
sub <- sample(nrow(data), floor(nrow(data) * 0.7))
trainData<-data[sub, ] #70 % for training
testData<-data[-sub, ] #30 % for testing
trainData
# Load libraries
library(rpart)
rpart.tree <- rpart(V10 ~ ., data=train.set)
trainData.set
tree <- rpart(V10 ~ ., data=trainData)
tree
plot(tree,margin=0.2)
text (tree, use.n = T, pretty = TRUE)
title("Training Set's Classification Tree")
plot(tree,margin=0.5)
text (tree, use.n = T, pretty = TRUE)
title("Training Set's Classification Tree")
plot(tree,margin=0.1)
text (tree, use.n = T, pretty = TRUE)
title("Training Set's Classification Tree")
plot(tree,margin=0.05)
text (tree, use.n = T, pretty = TRUE)
title("Training Set's Classification Tree")
title("Training tree")
tree <- rpart(V10 ~ ., data=trainData)
plot(tree,margin=0.05)
text (tree, use.n = T, pretty = TRUE)
title("Training tree")
predictions <- predict(tree, testData, type="class")
predictions <- predict(tree, testData, type="class")
# Create the tree
tree <- rpart(V10 ~ ., data=trainData)
plot(tree,margin=0.05)
text (tree, use.n = T, pretty = TRUE)
title("Training tree")
# Predictions
predictions <- predict(tree, testData, type="class")
predictions <- predict(tree, testData)
predictions
predictions <- predict(tree, testData, type="class")
data <- read.csv("cmc.data", header = FALSE, sep=",")
data$V10 <- factor(data$V10)
# Generate training and testing set
sub <- sample(nrow(data), floor(nrow(data) * 0.7))
trainData<-data[sub, ] #70 % for training
testData<-data[-sub, ] #30 % for testing
# Create the tree
tree <- rpart(V10 ~ ., data=trainData)
plot(tree,margin=0.05)
text (tree, use.n = T, pretty = TRUE)
title("Training tree")
# Predictions
predictions <- predict(tree, testData, type="class")
plot(tree,margin=0.2)
text (tree, use.n = T, pretty = TRUE)
title("Training tree")
# Predictions
predictions <- predict(tree, testData, type="class")
predictions
# Compare
table(testData$V10, predictions)
prune.rpart.tree <- prune(tree, cp=0.01)
plot(prune.rpart.tree,margin=0.2)
text (prune.rpart.tree, use.n = T, pretty = TRUE)
table(testData$V10, predictions)
sum(diag(results))
results <- table(testData$V10, predictions)
sum(diag(results))
sum(results)
accuracy <- sum(diag(results)) / sum(results)
accuracy
data <- read.csv("cmc.data", header = TRUE, sep=",")
data
data$contraceptive.method
library(rpart)
# Set the seed
set.seed(1111)
# Set working directory
setwd("/Users/nicolaslopezj/Code/r/bi/9-05")
# Set data
data <- read.csv("cmc.data", header = TRUE, sep=",")
data$contraceptive.method <- factor(data$contraceptive.method)
# Generate training and testing set
sub <- sample(nrow(data), floor(nrow(data) * 0.7))
trainData<-data[sub, ] #70 % for training
testData<-data[-sub, ] #30 % for testing
# Create the tree
tree <- rpart(contraceptive.method ~ ., data=trainData)
plot(tree,margin=0.2)
text (tree, use.n = T, pretty = TRUE)
title("Training tree")
# Predictions
predictions <- predict(tree, testData, type="class")
# Compare
results <- table(testData$contraceptive.method, predictions)
accuracy <- sum(diag(results)) / sum(results)
summary(data)
class(data$wife.age)
class(data$wife.education)
class(data$wife.islam)
data$contraceptive.method <- as.factor(data$contraceptive.method)
class(data$contraceptive.method)
as
as.bool
as.boolean
as.integer
summary(data)
as.binary
as
factor
bynary
binary
data <- read.csv("cmc.data", header = TRUE, sep=",")
data$wife.education <- as.factor(data$wife.education)
data$husband.education <- as.factor(data$husband.education)
data$wife.islam <- as.factor(data$wife.islam)
data$wife.work <- as.factor(data$wife.work)
data$husband.occupation <- as.factor(data$husband.occupation)
data$living.standard <- as.factor(data$living.standard)
data$media.exposure <- as.factor(data$media.exposure)
data$contraceptive.method <- as.factor(data$contraceptive.method)
# Generate training and testing set
sub <- sample(nrow(data), floor(nrow(data) * 0.7))
trainData<-data[sub, ] #70 % for training
testData<-data[-sub, ] #30 % for testing
# Create the tree
tree <- rpart(contraceptive.method ~ ., data=trainData)
plot(tree,margin=0.2)
text (tree, use.n = T, pretty = TRUE)
title("Training tree")
# Predictions
predictions <- predict(tree, testData, type="class")
# Compare
results <- table(testData$contraceptive.method, predictions)
accuracy <- sum(diag(results)) / sum(results)
accuracy
results
results0
results$1
results$"1"
results[1]
results[1, 1]
results[1,]
accuracy1 <- results[1] / sum(results[1,])
accuracy1
accuracy1 <- results[1] / sum(results[1,]) # accuracy 69%
accuracy2 <- results[2] / sum(results[2,]) # accuracy 69%
accuracy3 <- results[3] / sum(results[3,]) # accuracy 69%
accuracy2
accuracy3
summary(data)
tree
predictions
results
predictions
tree
bayes <- naiveBayes(contraceptive.method ~ ., data=trainData)
library(rpart)
library(e1071)
library(discretization)
library(infotheo)
bayes <- naiveBayes(contraceptive.method ~ ., data=trainData)
bayes
bayes <- naiveBayes(contraceptive.method ~ ., data=trainData)
# Predictions
predictionsBayes <- predict(bayes, testData, type="class")
# Compare
resultsBayes <- table(testData$contraceptive.method, predictionsBayes)
accuracyBayes <- sum(diag(resultsBayes)) / sum(resultsBayes) # accuracy 57%
accuracyBayes1 <- resultsBayes[1] / sum(resultsBayes[1,]) # accuracy 69%
accuracyBayes2 <- resultsBayes[2] / sum(resultsBayes[2,]) # accuracy 27%
accuracyBayes3 <- resultsBayes[3] / sum(resultsBayes[3,]) # accuracy 30%
accuracyBayes
accuracyBayes1
accuracyBayes12
accuracyBayes12
accuracyBayes2
accuracyBayes3
bayes2 <- naiveBayes(contraceptive.method ~ children.ever.born + wife.age + wife.education + wife.work + husband.occupation, data=trainData)
# Predictions
predictionsBayes2 <- predict(bayes2, testData, type="class")
# Compare
resultsBayes2 <- table(testData$contraceptive.method, predictionsBayes2)
accuracyBayes2 <- sum(diag(resultsBayes2)) / sum(resultsBayes2) # accuracy 50%
accuracyBayes21 <- resultsBayes2[1] / sum(resultsBayes2[1,]) # accuracy 52%
accuracyBayes22 <- resultsBayes2[2] / sum(resultsBayes2[2,]) # accuracy 19%
accuracyBayes23 <- resultsBayes2[3] / sum(resultsBayes2[3,]) # accuracy 22%
accuracyBayes2
accuracyBayes21
accuracyBayes22
accuracyBayes23
accuracyBayes2
resultsBayes2
results
Based on the confusion matrix of the previous question, what kind of contraceptive method is more difficult for the tree to predict? Justify your answer.
accuracy
resultsBayes
resultsBayes2
accuracyBayes23
accuracyBayes3
